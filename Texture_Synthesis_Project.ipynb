{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiroikenshi/Texture-Systhesis-Imagens/blob/main/Texture_Synthesis_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MdBr7jPHX8Y"
      },
      "source": [
        "## Universidade Cruzeiro do Sul\n",
        "\n",
        "\n",
        "## Processamento de Imagens\n",
        "\n",
        "### 1º Semestre de 2023\n",
        "<br></br>\n",
        "\n",
        "# Relatório do Projeto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFnNshNzHX8i"
      },
      "source": [
        "## Grupo\n",
        "\n",
        "\n",
        "*   Camila Ferreira de Sousa | RGM: 28396073\n",
        "*   Catherine Ferreira Honorato | RGM: 25971573\n",
        "*   Felipe Pinto da Silva | RGM: 26533952\n",
        "*   Hugo Nascimento Pedro | RGM: 26370174"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTE2x1PFre0a"
      },
      "source": [
        "---\n",
        "# Melhorando imagens com técnicas de Texture Synthesis\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM6gP-OpHX8j"
      },
      "source": [
        "## Resumo\n",
        "\n",
        "O tema do nosso projeto tem como objetivo melhorar a qualidade visual de imagens danificadas ou com baixa resolução através da implementação de técnicas da Síntese de Textura. Isso foi feito atráves de funções do OpenCV e de um modelo treinado de IA.\n",
        "\n",
        "### Prévia de resultados:\n",
        "<img src=\"https://raw.githubusercontent.com/shiroikenshi/Texture-Systhesis-Imagens/main/Prévias/previa1.png\">\n",
        "\n",
        "A primeira imagem apresenta defeitos e baixa resolução, na seguinte imagem as imperfeições são corrigidas e há o aumento da resolução.\n",
        "\n",
        "Na implementação dos algoritmos a imagem sofreu um upscale, devido alguns parametros adicionais na execução do script da rede neural, tornou-se possível recuperar detalhes anteriormente perdidos do rosto.\n",
        "\n",
        "<br><img src=\"https://raw.githubusercontent.com/shiroikenshi/Texture-Systhesis-Imagens/main/Prévias/previa2.png\">\n",
        "\n",
        "A primeira imagem apresenta uma baixa resolução, na segunda se vê uma melhora significativa na resolução dos detalhes.\n",
        "\n",
        "O macaco adquiriu traços humanos devido a rede neural ter sido treinada com uma base de dados de rostos humanos, portanto ao corrigir a imagem com um parâmetro de melhoramento de rostos, este macaco recebe um aspecto humanizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xea89nClp4BS"
      },
      "source": [
        "## Introdução \n",
        "\n",
        "O tema escolhido pelo nosso grupo foi a Síntese de Texturas, em uma rápida definição se trata de uma tecnica computacional que tem como objetivo criar novas texturas a partir de uma amostra existente. Isso é feito através de algoritmos que analisam a textura original e a reproduzem de forma coerente em uma área maior ou menor, dependendo da necessidade.\n",
        "\n",
        "Nesse projeto vamos implementar dois algoritmos de síntese de Textura:\n",
        "\n",
        "1. Inpainting - Técnica de processamento de imagens que permite remover ou preencher áreas faltantes ou danificadas em uma imagem, de forma a reconstruir a informação perdida. \n",
        "2. Super-resolução com rede neural - Técnica de processamento de imagens que permite aumentar a resolução de uma imagem, de forma a obter uma versão mais detalhada e nítida, utilizando um modelo de pré treinado de rede neural.\n",
        "\n",
        "Considerando essas técnicas, escolhemos imagens de repositórios públicos no github utilizando dois critérios:\n",
        "\n",
        "1. Imagens danificadas e com baixa resolução pra implementar uma técnica seguida da outra, resultando em uma imagem tratada e restaurada a partir desses dois algoritmos.\n",
        "2. Imagens com baixa resolução e com muitos detalhes para ver como a rede neural se sairia ao aplicar a super-resolução."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj6LXiA6qxZr"
      },
      "source": [
        "## Objetivo\n",
        "\n",
        "O objetivo do projeto é implementar as técnicas de Inpainting e Super-resolução com rede neural em imagens danificadas e de baixa resolução, com o intuito de restaurar e melhorar sua qualidade.\n",
        "\n",
        "*   O Inpainting será utilizado para remover áreas danificadas ou objetos indesejados da imagem.\n",
        "*   Enquanto a Super-resolução com rede neural será aplicada para aumentar a resolução das imagens e melhorar sua nitidez e qualidade visual.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gGBEwgOtQLk"
      },
      "source": [
        "## Desenvolvimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkrDX_4htzg0"
      },
      "source": [
        "#### Parte 1 - Importação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I33x0TXQuUZc"
      },
      "source": [
        "O primeiro passo do nosso algoritmo é executar o código responsável por clonar nosso repositório de imagens do github para o diretório do colab, nesse projeto, em vez de fornecermos um url de imagem para as variáveis, vamos trabalhar fornecendo seu caminho no diretório do colab, portanto essa é uma etapa essencial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgnLL7FCphWz"
      },
      "outputs": [],
      "source": [
        "# Clona nosso repositório de imagens para o diretório do colab\n",
        "!git clone https://github.com/shiroikenshi/Texture-Systhesis-Imagens.git /content/imagens -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrPOSVaFuNUT"
      },
      "source": [
        "Prosseguindo, temos o código responsável por importar diversas bibliotecas úteis para a manipulação de imagens, além de bibliotecas para a interação com o sistema operacional e com o notebook em si, exibição de conteúdos HTML, execução de javascript e a (codi/deco)dificação de dados base64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMTqzGv3ukHf"
      },
      "outputs": [],
      "source": [
        "# Biblioteca OpenCV para manipulação de imagens\n",
        "import cv2\n",
        "\n",
        "# Classes da bibioteca IPython para exibição de conteúdo HTML, imagens e objetos (canvas)\n",
        "from IPython.display import HTML, Image, display\n",
        "\n",
        "# Biblioteca para codificação e decodificação de dados em base64 / biblioteca para interação com o sistema operacional (base64 canvas)\n",
        "import base64, os\n",
        "from base64 import b64decode\n",
        "\n",
        "# Função da biblioteca google.colab.output para executar código JavaScript no notebook\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "# Pacote de funções para plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pacote NumPy para manipulação de arrays\n",
        "import numpy as np\n",
        "\n",
        "# Shutil para fazer a manipulação de arquivos e pastas no diretório\n",
        "import shutil\n",
        "\n",
        "# Glob para ajudar a rede neural a encontrar arquivos em listas com um padrão pré determinado\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDOYFnjNul60"
      },
      "source": [
        "Por fim, este código baixa e configurar as bibliotecas necessárias para utilizar a rede neural (Real-ESRGAN), que será responsável por aplicar a super-resolução nas nossas imagens, além de seu modelo pré-treinado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAZB7GHPzaC0"
      },
      "outputs": [],
      "source": [
        "# Clona o repositório do Real-ESRGAN para o diretório do colab\n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git -q\n",
        "# Acessa o diretório do Real-ESRGAN (content/Real-ESRGAN)\n",
        "%cd Real-ESRGAN\n",
        "\n",
        "# Instala as bibliotecas necessárias\n",
        "!pip install basicsr -q\n",
        "!pip install facexlib -q\n",
        "!pip install gfpgan -q\n",
        "# Instala os requisitos definidor no arquivo requirements.txt\n",
        "!pip install -r requirements.txt -q\n",
        "# Configura o Real-ESRGAN usando o arquivo setup.py\n",
        "!python setup.py develop -q\n",
        "\n",
        "# Baixa o modelo pré-treinado RealESRGAN_x4plus.pth para o diretório experiments/pretrained_models\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n",
        "# Retorna para o diretório anterior (content)\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YEUOKd7zL-v"
      },
      "source": [
        "#### Parte 2 - Implementação do canvas e das funções"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obs: A função do openCV recebe dois paramentros do usuário para realizar o inpainting, um arquivo de imagem, e outro de máscara, que irá servir de referência para o tratamento da imagem. Pensando nisso implementamos o algoritmo de uma forma que o usuário possa fornecer um arquivo de máscara, ou desenhar uma nova a partir de um painel interativo."
      ],
      "metadata": {
        "id": "NWCzdv0FMyyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código cria o canvas_html responsável por exibir uma interface interativa para o usuário desenhar a própria máscara, conta com um botão de finalização, duas camadas de canvas (uma com a imagem de referência e outra transparente que será pincelada) e o código em javascript para capturar os dados do mouse."
      ],
      "metadata": {
        "id": "JtsEoBGvKTZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando canvas_html para exibir ao usuário um display interativo para criar a própria máscara\n",
        "canvas_html = \"\"\"\n",
        "<style>\n",
        ".button {\n",
        "  display: inline-block;\n",
        "  padding: 15px 40px;\n",
        "  font-size: 16px;       \n",
        "  cursor: pointer;\n",
        "  text-align: center;\n",
        "  text-decoration: none;\n",
        "  outline: none;\n",
        "  color: #fff;\n",
        "  background-color: #8c8c8c;\n",
        "  border: none;\n",
        "  border-radius: 10px;\n",
        "  margin: 8px 0px 15px 0px;\n",
        "}\n",
        "\n",
        ".button:hover {background-color: #474747}\n",
        "\n",
        ".button:active {\n",
        "  background-color: #339966;\n",
        "  box-shadow: 0 5px #666;\n",
        "  transform: translateY(4px);\n",
        "}\n",
        "</style>\n",
        "\n",
        "<canvas1 width=%d height=%d>\n",
        "</canvas1>\n",
        "\n",
        "<canvas width=%d height=%d>\n",
        "</canvas>\n",
        "<br>\n",
        "\n",
        "<button class=\"button\">Finalizar</button>\n",
        "\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "\n",
        "var canvas1 = document.querySelector('canvas1')\n",
        "var ctx1 = canvas.getContext('2d')\n",
        "\n",
        "ctx.strokeStyle = 'red';\n",
        "\n",
        "var img = new Image();\n",
        "img.src = \"data:image/%s;charset=utf-8;base64,%s\";\n",
        "console.log(img)\n",
        "img.onload = function() {\n",
        "  ctx1.drawImage(img, 0, 0);\n",
        "};\n",
        "img.crossOrigin = 'Anonymous';\n",
        "\n",
        "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Explicando linha por linha do script do canvas\n",
        "# var canvas = document.querySelector('canvas'): Seleciona o elemento HTML canvas\n",
        "# var ctx = canvas.getContext('2d'): Define o contexto 2D do canvas, onde serão desenhados os traços da máscara\n",
        "# var canvas1 = document.querySelector('canvas1'): Seleciona o elemento HTML canvas1\n",
        "# var ctx1 = canvas.getContext('2d'): Define o contexto 2D do canvas1, onde será carregada a imagem da máscara\n",
        "# ctx.strokeStyle = 'red': Define a cor dos traços da máscara como vermelho\n",
        "# var img = new Image(): Cria um novo objeto de imagem\n",
        "# img.src = \"data:image/%s;charset=utf-8;base64,%s\": Define o caminho da imagem da máscara, utilizando a codificação em base64\n",
        "# console.log(img): Exibe o objeto imagem no console\n",
        "# img.onload = function() {...}: Define uma função a ser executada quando a imagem da máscara for carregada\n",
        "# ctx1.drawImage(img, 0, 0): Desenha a imagem da máscara no canvas1\n",
        "# img.crossOrigin = 'Anonymous': Define o atributo crossOrigin do objeto imagem como 'Anonymous', permitindo o carregamento de imagens de outras origens\n",
        "# ctx.clearRect(0, 0, canvas.width, canvas.height): Limpa o canvas antes de desenhar a máscara\n",
        "# ctx.lineWidth = %d: Define a largura dos traços da máscara\n",
        "# var button = document.querySelector('button'): Seleciona o elemento HTML button\n",
        "# var mouse = {x: 0, y: 0}: Cria um objeto com as coordenadas iniciais do mouse\n",
        "# canvas.addEventListener('mousemove', function(e) {...}): Adiciona um evento de movimento do mouse ao canvas\n",
        "# canvas.onmousedown = () => {...}: Adiciona um evento de clique do mouse ao canvas\n",
        "# ctx.beginPath(): Inicia um novo traço da máscara\n",
        "# ctx.moveTo(mouse.x, mouse.y): Define o ponto inicial do traço como a posição atual do mouse\n",
        "# canvas.addEventListener('mousemove', onPaint): Adiciona um evento de movimento do mouse ao canvas, executando a função onPaint\n",
        "# canvas.onmouseup = () => {...}: Adiciona um evento de soltura do clique do mouse ao canvas\n",
        "# canvas.removeEventListener('mousemove', onPaint): Remove o evento de movimento do mouse do canvas, que executa a função onPaint\n",
        "# var onPaint = () => {...}: Define a função onPaint, que desenha o traço da máscara no canvas\n",
        "# ctx.lineTo(mouse.x, mouse.y): Define o ponto final do traço como a posição atual do mouse\n",
        "# ctx.stroke(): Desenha o traço no canvas\n",
        "# var data = new Promise(resolve => {...}): Cria uma Promise que resolve com o conteúdo do canvas quando o botão de finalizar é clicado\n",
        "# button.onclick = () => {...}: Adiciona um evento de clique do botão de finalizar\n",
        "# resolve(canvas.toDataURL('image/png')): Resolve a Promise com a imagem da máscara em formato PNG codificada em base64"
      ],
      "metadata": {
        "id": "nfjQ2AmsKMkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prosseguindo temos o código responsável por criar a função \"draw\", que irá exibir o canvas_html para o usuário através de um display."
      ],
      "metadata": {
        "id": "3IzRp-BeK2Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando função draw()\n",
        "def draw(imgm, filename='drawing.png', w=400, h=200, line_width=1):\n",
        "  # Exibe a interface gráfica com o canvas_html\n",
        "  display(HTML(canvas_html % (w, h, w,h, filename.split('.')[-1], imgm, line_width)))\n",
        "  # Obtém os dados gerados pela interação do usuário no canvas e armazena na variável \"data\"\n",
        "  data = eval_js(\"data\")\n",
        "  # Decodifica os dados da variável \"data\" e armazena em \"binary\"\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  # Escreve os dados em \"binary\" no arquivo especificado em \"filename\", definodo por \"drawing.png\"\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)"
      ],
      "metadata": {
        "id": "Oa0yt77vK2eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código cria uma função com o nome \"path\" que é responsável por pedir ao usuário um caminho de arquivo dentro do diretório do colab, será através dele que iremos escolher as imagens a serem tratadas, caso o caminho seja inválido ele retorna uma mensagem de erro e volta ao começo do loop."
      ],
      "metadata": {
        "id": "m9oblcBXLhp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando função path(), recebe uma string 'x' como parametro com fins informativos para o usuário\n",
        "def path(x):\n",
        "  # Cria um loop \n",
        "  while True:\n",
        "    # Pede ao usuário um caminho de arquivo (imagem ou máscara)\n",
        "    path = input(f\"Digite o caminho do arquivo de {x}: \")\n",
        "    # Tenta abrir o arquivo utilizando o caminho informado com a função open\n",
        "    try:\n",
        "      with open(path, 'rb'):\n",
        "        # Caso o caminho seja válido a função retorna esse caminho\n",
        "        return path\n",
        "    # Caso ocorra um erro de FileNotFoundError exibe uma mensagem de erro e retorna ao começo do loop\n",
        "    except FileNotFoundError:\n",
        "      print(\"Caminho inválido, tente novamente!\")"
      ],
      "metadata": {
        "id": "wMUAfY3aLkb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parte 3 - Implementação do Inpainting"
      ],
      "metadata": {
        "id": "ibbh69jwJH8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nossa implementação começa com um código que escolhe a imagem a ser carregada através da função path anteriormente definida, e depois a exibe com a função plot."
      ],
      "metadata": {
        "id": "ZOtfOfldOsd0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvKbRnXoD1yr"
      },
      "outputs": [],
      "source": [
        "# Carrega a imagem original\n",
        "image_file = path(\"imagem\")\n",
        "img = cv2.imread(image_file)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Exibe a imagem original\n",
        "print(\"\\n\")\n",
        "plt.imshow(img)\n",
        "plt.title('Imagem Original')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prosseguindo, nós temos um while que pergunta se o usuário deseja desenhar uma mascara manualmente, chamando então a função draw anteriormente definida, ou se ele deseja fornecer um arquivo de máscara, após a escolha a imagem e a máscara passam pela função de inpainting e o resultado é por fim exibido em um plot."
      ],
      "metadata": {
        "id": "loR9NwlzPSZy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-yyoenpmJny"
      },
      "outputs": [],
      "source": [
        "# Loop para captura de erros na entrada de dados\n",
        "while True:\n",
        "  # Pergunta se deseja desenhas máscara manualmente ou fornecer um arquivo\n",
        "  mask_choice = input(\"Deseja desenhar a máscara manualmente (1) ou fornecer um arquivo (2)? \")\n",
        "  # Verifica se o valor no input é válido\n",
        "  if mask_choice == \"1\" or mask_choice == \"2\":\n",
        "    break\n",
        "  print(\"Entrada inválida!\")\n",
        "\n",
        "# Essa parte é necessária para exibir uma imagem de referência rgb ao invés de bgr no canvas\n",
        "# Salva a imagem em um arquivo temporário\n",
        "temp_file = \"./imagens/temp_image.png\"\n",
        "# Converte de BGR para RGB\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "# Salva imagem processada em arquivo temporário\n",
        "cv2.imwrite(temp_file, img_rgb)\n",
        "\n",
        "# Desenha máscara manualmente\n",
        "if mask_choice == \"1\":\n",
        "  print(\"\\n\")\n",
        "  # Abre o arquivo temporário para leitura em bytes\n",
        "  with open(temp_file, \"rb\") as f:\n",
        "      image_bytes = f.read()\n",
        "      image64 = base64.b64encode(image_bytes)\n",
        "      image64 = image64.decode('utf-8')\n",
        "\n",
        "  # Chama a função draw() para desenhar a máscara manualmente\n",
        "  draw(image64, filename=f\"./imagens/temp_image_mask.png\", w=img.shape[1], h=img.shape[0], line_width=0.03*img.shape[1])\n",
        "\n",
        "  # Carrega a imagem da máscara desenhada e converte para um array numpy\n",
        "  with_mask = np.array(plt.imread(f\"./imagens/temp_image_mask.png\")[:,:,:3])\n",
        "\n",
        "  # Cria uma máscara binária a partir da imagem com máscara\n",
        "  mask = (with_mask[:,:,0]==1)*(with_mask[:,:,1]==0)*(with_mask[:,:,2]==0)\n",
        "  mask = mask.astype('uint8')\n",
        "\n",
        "# Fornece arquivo de máscara\n",
        "elif mask_choice == \"2\":\n",
        "  # Pede ao usuário o caminho para o arquivo de máscara\n",
        "  mask_file = path(\"máscara\")\n",
        "  print(\"\\n\")\n",
        "  # Converte o arquivo de máscara para escala de cinza\n",
        "  mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Aplica o inpainting na imagem utilizando a máscara criada\n",
        "inpaint = cv2.inpaint(img, mask, 2, cv2.INPAINT_TELEA)\n",
        "\n",
        "# Salva uma cópia da imagem que sofreu inpainting (e passa para rgb)\n",
        "inpaint_rgb = cv2.cvtColor(inpaint, cv2.COLOR_BGR2RGB)\n",
        "cv2.imwrite(\"./imagens/inpaint.png\", inpaint_rgb)\n",
        "\n",
        "# Exibe as imagens\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15,8));\n",
        "\n",
        "# Exibe a primeira imagem na plotagem\n",
        "axs[0].imshow(img, cmap=\"gray\");\n",
        "axs[0].set_title('Original') ;\n",
        "axs[0].axis(\"off\");\n",
        "\n",
        "# Exibe a segunda imagem na plotagem\n",
        "axs[1].imshow(mask, cmap=\"gray\");\n",
        "axs[1].set_title('Máscara');\n",
        "axs[1].axis(\"off\");\n",
        "\n",
        "# Exibe a terceira imagem na plotagem\n",
        "axs[2].imshow(inpaint, cmap=\"gray\");\n",
        "axs[2].set_title('Inpainting');\n",
        "axs[2].axis(\"off\");\n",
        "\n",
        "# Exibe as imagens\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6RNXQmSzTsX"
      },
      "source": [
        "#### Parte 4 - Implementação da rede neural de Super-Resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assim como no código anterior, esse também começa com um while, porém perguntando se o usuário deseja utilizar a imagem que sofreu inpainting, ou fornecer outra, quando a escolha é efetivada a imagem é então exibida através de um plot e armazenada dentro do upload_folder da rede neural."
      ],
      "metadata": {
        "id": "8uSYfipqRm7v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrjpXWatPRSm"
      },
      "outputs": [],
      "source": [
        "# Loop para captura de erros na entrada de dados\n",
        "while True:\n",
        "  # Pergunta se deseja utilizar a imagem que sofreu inpainting ou fornecer outra imagem\n",
        "  image_choice = input(\"Deseja utilizar a imagem que sofreu inpainting (1) ou fornecer outra imagem (2)? \")\n",
        "  # Verifica se o valor no input é válido\n",
        "  if image_choice == \"1\" or image_choice == \"2\":\n",
        "    break\n",
        "  print(\"Entrada inválida!\")\n",
        "\n",
        "# Escolhe imagem que sofreu inpainting\n",
        "if image_choice == \"1\":\n",
        "  image_file = \"/content/imagens/inpaint.png\"\n",
        "\n",
        "# Escolhe outra imagem\n",
        "elif image_choice == \"2\":\n",
        "  image_file = path(\"imagem\")\n",
        "\n",
        "# Carrega a imagem original\n",
        "img = cv2.imread(image_file)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Exibe a imagem original\n",
        "print(\"\\n\")\n",
        "plt.imshow(img)\n",
        "plt.title('Imagem Original')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Acessa o diretório do Real-ESRGAN (content/Real-ESRGAN)\n",
        "%cd Real-ESRGAN\n",
        "\n",
        "# Define os diretórios de upload e results\n",
        "upload_folder = 'upload'\n",
        "result_folder = 'results'\n",
        "\n",
        "# Verifica se os diretórios de upload e result já existem, caso existam, são removidos\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "if os.path.isdir(result_folder):\n",
        "    shutil.rmtree(result_folder)\n",
        "\n",
        "# Cria os diretórios de upload e results\n",
        "os.mkdir(upload_folder)\n",
        "os.mkdir(result_folder)\n",
        "\n",
        "# Copia a imagem escolhida para a pasta upload\n",
        "shutil.copy(image_file, upload_folder)\n",
        "\n",
        "# Retorna para o diretório anterior (content)\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proseguindo, essa parte do código roda a rede neural (Real-ERSGAN) na imagem escolhida, podemos adaptar a imagem de saída de acordo com os parametros utilizados na execução do script, como a proposta desse tópico é super-resolução, preferimos prosseguir apenas com esses parametros."
      ],
      "metadata": {
        "id": "hYfT09G4SVjs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIEPxY_iR61B"
      },
      "outputs": [],
      "source": [
        "# Acessa o diretório do Real-ESRGAN (content/Real-ESRGAN)\n",
        "%cd Real-ESRGAN\n",
        "\n",
        "# Executa o script \"inference_realesrgan.py\" na imagem passando alguns parâmetros como modelo\n",
        "!python inference_realesrgan.py -n RealESRGAN_x4plus -i upload --outscale 4 --face_enhance\n",
        "\n",
        "# Parâmetro para aplicar a super-resolução: --outscale 4\n",
        "# Parametro para melhorar rostos humanos: --face_enhance\n",
        "\n",
        "# Retorna para o diretório anterior (content)\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalizando, essa parte do código é responsável por carregar a imagem tratada com a rede neural dentro da variável superresolution, que é posteriormente exibida junto com sua versão original pelo plot."
      ],
      "metadata": {
        "id": "VY6vxmFMTLuC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY6ngG-0SFgh"
      },
      "outputs": [],
      "source": [
        "# Carrega a imagem que sofreu super-resolução\n",
        "superresolution = cv2.imread(glob.glob('/content/Real-ESRGAN/results/*.png')[0])\n",
        "superresolution = cv2.cvtColor(superresolution, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Exibe as imagens\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15,8));\n",
        "\n",
        "# Exibe a primeira imagem na plotagem\n",
        "axs[0].imshow(img, cmap=\"gray\");\n",
        "axs[0].set_title('Original') ;\n",
        "axs[0].axis(\"off\");\n",
        "\n",
        "# Exibe a segunda imagem na plotagem\n",
        "axs[1].imshow(superresolution, cmap=\"gray\");\n",
        "axs[1].set_title('Super-Resolution');\n",
        "axs[1].axis(\"off\");\n",
        "\n",
        "# Exibe as imagens\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUJHidhButBm"
      },
      "source": [
        "## Conclusão\n",
        "\n",
        "Resultados obtidos:\n",
        "\n",
        "* Os resultados obtidos foram satisfatórios, as imagens foram de fato restauradas e melhoradas de forma significativa.\n",
        "* A rede neural obteve os melhores resultados, produzindo imagens de alta resolução e detalhes precisos.\n",
        "* Os modelos obtidos contribuiram para a resolução do problema inicial, as técnicas utilizadas possibilitaram recuperar informações perdidas, fazer remoção de objetos das imagens e melhorar a resolução.\n",
        "\n",
        "Dificuldades:\n",
        "\n",
        "* Na tentativa de implementar a IA, percebeu-se que algumas redes neurais são incompatíveis com o colab.\n",
        "* O poder computacional (GPU) do colab é limitado, após alguma interação a rede neural para de funcionar.\n",
        "\n",
        "Resoluções:\n",
        "\n",
        "* O uso de redes neurais compatíveis com o ambiente colab.\n",
        "* Possibilidade de assinar o colab para maior poder computacional, utilizar ambiente de execução local ou alternar as contas do google ao alcançar limite de GPU.\n",
        "\n",
        "Formas de continuidade: \n",
        "\n",
        "* Melhorar o canvas da função draw para possibilitar o usuário de corrigir seleções indesejadas na imagem com o atalho crtl+z.\n",
        "* Implementar o inpainting em tempo real, o usuário seleciona a área e aplica o inpaint ao soltar o click.\n",
        "* Melhora nas imperfeições que a função do inpaint do OpenCV não é capaz de corrigir, implementando outra rede neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVDPt8K2vTIF"
      },
      "source": [
        "## Referências\n",
        "\n",
        "###Parte 1 - Importação dos dados\n",
        "\n",
        "1. Importanto/clonando repositórios - https://stackoverflow.com/questions/48350226/methods-for-using-git-with-google-colab.\n",
        "2. Documentação do OpenCV - https://docs.opencv.org/4.x/.\n",
        "3. Documentação do IPython - https://ipython.readthedocs.io/en/stable/.\n",
        "4. Documentação do Base64 - https://docs.python.org/3/library/base64.html.\n",
        "5. Como utilizar js no notebook - https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb.\n",
        "6. Documentação do Matplotlib - https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html.\n",
        "7. Documentação do Numpy - https://numpy.org/doc/1.23/numpy-ref.pdf.\n",
        "8. Documentação do Shutil - https://docs.python.org/3/library/shutil.html.\n",
        "9. Documentação do Glob - https://docs.python.org/3/library/glob.html.\n",
        "10. Documentação da rede neural Real-ESRGAN - https://github.com/xinntao/Real-ESRGAN/blob/master/README.md.\n",
        "\n",
        "###Parte 2 - Implementação do canvas e das funções\n",
        "\n",
        "11. Como utilizar o canvas - https://developer.mozilla.org/pt-BR/docs/Web/API/Canvas_API/Tutorial.\n",
        "12. Como tratar erros com try e except - https://www.hashtagtreinamentos.com/try-e-except-no-python.\n",
        "\n",
        "###Parte 3 - Implementação do Inpainting\n",
        "\n",
        "13. Como utilizar a função inpaint - https://docs.opencv.org/3.4/df/d3d/tutorial_py_inpainting.html.\n",
        "\n",
        "###Parte 4 - Implementação da rede neural de Super-Resolution\n",
        "\n",
        "14. Manipulando diretórios com Shutil - https://code-maven.com/slides/python/os-dir."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MkrDX_4htzg0",
        "9YEUOKd7zL-v",
        "ibbh69jwJH8P",
        "z6RNXQmSzTsX"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}